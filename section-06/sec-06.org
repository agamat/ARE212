#+INCLUDE: ../orgpreamble.org

*Empirical example: return to education* \hfill
*ARE212*: Section 06 \\ \\

* Maximum Likelihood

Suppose that I tell you that $\X$ is a random vector, where each
$\X_i$ is generated from a common density function $\theta / (\theta +
\X_i)^2$.  We want to estimate $\theta$ by maximum likelihood, given
the data set =mle.txt= from Freedman (2009).  It can be shown that the
log-likelihood function is given by the following, where $n$ is the
number of observations: $$\like = n \log \theta - 2 \sn{i}
\log(\theta + \X_i)$$ First, we will plot the log-likelihood function
as a function of $\theta$, and then find the maximum with =optimize=.

#+begin_src R :results output graphics :exports both :tangle yes :session
  data <- read.csv("mle.txt", header = FALSE)
  data <- read.csv("http://dl.dropbox.com/u/5365589/mle.txt", header = FALSE)

  logLik <- function(theta, X = data) {
    n <<- nrow(X)
    n * log(theta) - 2 * sum(log(theta + X))
  }
#+end_src

#+RESULTS:

To maximize this function with respect to $\theta$, we don't have to
do any math.  And in fact, for this function, there is no explicit
function for the maximum likelihood estimate, and we have to find the
estimate through numerical optimization.

#+begin_src R :results output graphics :exports both :tangle yes :session
  optimize(logLik, interval=c(-100, 100), maximum=TRUE)
  suppressWarnings(opt <- optimize(logLik, interval=c(-100, 100), maximum=TRUE))
  (theta.hat <- opt$maximum)
#+end_src

#+RESULTS:
: [1] 22.50976

We can compute the asymptotic variance in a variety of ways, but
perhaps the most direct is $[- \likepp]^{-1}$:

#+begin_src R :results output graphics :exports both :tangle yes :session
  dd.logLik <- function(theta, X = data) {
    -1 * (n / theta^2) + 2 * sum(1 / (theta + X)^2)
  }

  (asy.var <- -1 / dd.logLik(theta.hat))
#+end_src

#+RESULTS:
: [1] 30.12326
